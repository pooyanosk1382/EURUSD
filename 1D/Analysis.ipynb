{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8333.   8448.   9324. ... -17691. -17911. -18229.]\n",
      "[  8449.   9324.   8833. ... -17908. -18228. -18049.]\n",
      "[1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"1D.csv\")\n",
    "dataset = dataset.iloc[11:, :]*10**5 - 127873\n",
    "openVal = dataset.iloc[:, 34]\n",
    "closeVal = dataset.iloc[:, 37]\n",
    "openVal = openVal\n",
    "closeVal = closeVal\n",
    "openVal = openVal.values\n",
    "closeVal = closeVal.values\n",
    "test = []\n",
    "for i in range(len(openVal)):\n",
    "    if closeVal[i] - openVal[i] < 0:\n",
    "        test.append(0)\n",
    "    else:\n",
    "        test.append(1)\n",
    "print(openVal)\n",
    "print(closeVal)\n",
    "print(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32516.0\n",
      "-32516.0\n"
     ]
    }
   ],
   "source": [
    "print(max(dataset.iloc[:, 1:].max()))\n",
    "print(min(dataset.iloc[:, 1:].min()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find high value by open value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9981.  10146.   9730. ...   9648.   8366.   8333.]\n",
      " [  9861.  10101.   9707. ...   8542.   8185.   8448.]\n",
      " [ 10059.  10437.   9692. ...   9401.   8302.   9324.]\n",
      " ...\n",
      " [-17300. -17203. -18232. ... -17645. -17732. -17691.]\n",
      " [-18095. -16921. -18190. ... -17338. -17920. -17911.]\n",
      " [-17423. -17239. -17953. ... -17866. -18463. -18229.]]\n",
      "[[  8542.]\n",
      " [  9401.]\n",
      " [  9367.]\n",
      " ...\n",
      " [-17338.]\n",
      " [-17866.]\n",
      " [-17805.]]\n"
     ]
    }
   ],
   "source": [
    "x = dataset.iloc[:, 1:35]\n",
    "y = dataset.iloc[:,   35]\n",
    "x = x.values\n",
    "y = y.values\n",
    "y = y.reshape(len(y),1)\n",
    "print(x)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)",
      "text/html": "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "regressorHigh = XGBRegressor()\n",
    "regressorHigh.fit(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8761.1    8542.  ]\n",
      " [  9055.73   9401.  ]\n",
      " [  9569.13   9367.  ]\n",
      " ...\n",
      " [-17419.68 -17338.  ]\n",
      " [-17775.02 -17866.  ]\n",
      " [-17734.56 -17805.  ]]\n"
     ]
    }
   ],
   "source": [
    "yPredHigh = regressorHigh.predict((x[:, :]))\n",
    "np.set_printoptions(precision=2)\n",
    "y = dataset.iloc[:, 35]\n",
    "y = y.values\n",
    "print(np.concatenate((yPredHigh.reshape(len(yPredHigh), 1), y.reshape(len(y), 1)), 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9998385932268274"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y, yPredHigh)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166.9481811523438\n",
      "128.80806095167117\n"
     ]
    }
   ],
   "source": [
    "diffHigh = []\n",
    "for i in range(len(y)):\n",
    "    diffHigh.append(abs(y[i] - yPredHigh[i]))\n",
    "print(max(diffHigh))\n",
    "print(np.mean(diffHigh))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find next low"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9981.    10146.     9730.   ...   8366.     8333.     8761.1 ]\n",
      " [  9861.    10101.     9707.   ...   8185.     8448.     9055.73]\n",
      " [ 10059.    10437.     9692.   ...   8302.     9324.     9569.13]\n",
      " ...\n",
      " [-17300.   -17203.   -18232.   ... -17732.   -17691.   -17419.68]\n",
      " [-18095.   -16921.   -18190.   ... -17920.   -17911.   -17775.02]\n",
      " [-17423.   -17239.   -17953.   ... -18463.   -18229.   -17734.56]]\n"
     ]
    }
   ],
   "source": [
    "x = dataset.iloc[:, 1:35]\n",
    "x = x.values\n",
    "x = np.concatenate((x, yPredHigh.reshape(len(yPredHigh), 1)), 1)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8185.]\n",
      " [  8302.]\n",
      " [  8763.]\n",
      " ...\n",
      " [-17920.]\n",
      " [-18463.]\n",
      " [-18459.]]\n"
     ]
    }
   ],
   "source": [
    "y = dataset.iloc[:, 36]\n",
    "y = y.values\n",
    "y = y.reshape(len(y),1)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)",
      "text/html": "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "regressorLow = XGBRegressor()\n",
    "regressorLow.fit(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8145.76   8185.  ]\n",
      " [  8192.64   8302.  ]\n",
      " [  8930.86   8763.  ]\n",
      " ...\n",
      " [-17939.04 -17920.  ]\n",
      " [-18253.61 -18463.  ]\n",
      " [-18485.23 -18459.  ]]\n"
     ]
    }
   ],
   "source": [
    "yPredLow = regressorLow.predict((x[:, :]))\n",
    "np.set_printoptions(precision=2)\n",
    "y = dataset.iloc[:, 36].values\n",
    "print(np.concatenate((yPredLow.reshape(len(yPredLow), 1), y.reshape(len(y), 1)), 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "0.999853394298373"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y, yPredLow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300.095703125\n",
      "121.80190056870153\n"
     ]
    }
   ],
   "source": [
    "diffLow = []\n",
    "for i in range(len(y)):\n",
    "    diffLow.append(abs(y[i] - yPredLow[i]))\n",
    "print(max(diffLow))\n",
    "print(np.mean(diffLow))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find close"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9981.    10146.     9730.   ...   8333.     8761.1    8145.76]\n",
      " [  9861.    10101.     9707.   ...   8448.     9055.73   8192.64]\n",
      " [ 10059.    10437.     9692.   ...   9324.     9569.13   8930.86]\n",
      " ...\n",
      " [-17300.   -17203.   -18232.   ... -17691.   -17419.68 -17939.04]\n",
      " [-18095.   -16921.   -18190.   ... -17911.   -17775.02 -18253.61]\n",
      " [-17423.   -17239.   -17953.   ... -18229.   -17734.56 -18485.23]]\n"
     ]
    }
   ],
   "source": [
    "x = dataset.iloc[:, 1:35]\n",
    "x = x.values\n",
    "x = np.concatenate((x, yPredHigh.reshape(len(yPredHigh), 1)), 1)\n",
    "x = np.concatenate((x, yPredLow.reshape(len(yPredLow), 1)), 1)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8449.]\n",
      " [  9324.]\n",
      " [  8833.]\n",
      " ...\n",
      " [-17908.]\n",
      " [-18228.]\n",
      " [-18049.]]\n"
     ]
    }
   ],
   "source": [
    "y = dataset.iloc[:, 37]\n",
    "y = y.values\n",
    "y = y.reshape(len(y),1)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)",
      "text/html": "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "regressorClose = XGBRegressor()\n",
    "regressorClose.fit(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8344.37   8449.  ]\n",
      " [  8925.7    9324.  ]\n",
      " [  9071.54   8833.  ]\n",
      " ...\n",
      " [-17745.12 -17908.  ]\n",
      " [-18115.11 -18228.  ]\n",
      " [-18061.7  -18049.  ]]\n"
     ]
    }
   ],
   "source": [
    "yPredClose = regressorClose.predict((x[:, :]))\n",
    "np.set_printoptions(precision=2)\n",
    "y = dataset.iloc[:, 37].values\n",
    "print(np.concatenate((yPredClose.reshape(len(yPredClose), 1), y.reshape(len(y), 1)), 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9998748513151869"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y, yPredClose)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093.1818847656396\n",
      "114.69564001387374\n"
     ]
    }
   ],
   "source": [
    "diffClose = []\n",
    "for i in range(len(y)):\n",
    "    diffClose.append(abs(y[i] - yPredClose[i]))\n",
    "print(max(diffClose))\n",
    "print(np.mean(diffClose))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checking ascending"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9981.    10146.     9730.   ...   8333.     8761.1    8145.76]\n",
      " [  9861.    10101.     9707.   ...   8448.     9055.73   8192.64]\n",
      " [ 10059.    10437.     9692.   ...   9324.     9569.13   8930.86]\n",
      " ...\n",
      " [-17300.   -17203.   -18232.   ... -17691.   -17419.68 -17939.04]\n",
      " [-18095.   -16921.   -18190.   ... -17911.   -17775.02 -18253.61]\n",
      " [-17423.   -17239.   -17953.   ... -18229.   -17734.56 -18485.23]]\n"
     ]
    }
   ],
   "source": [
    "x = dataset.iloc[:, 1:35]\n",
    "x = x.values\n",
    "x = np.concatenate((x, yPredHigh.reshape(len(yPredHigh), 1)), 1)\n",
    "x = np.concatenate((x, yPredLow.reshape(len(yPredLow), 1)), 1)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n              predictor=None, random_state=None, ...)",
      "text/html": "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifierAscending = XGBClassifier()\n",
    "classifierAscending.fit(x, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2331   74]\n",
      " [  45 2489]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9759060538570561"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "yPred = classifierAscending.predict(x)\n",
    "cm = confusion_matrix(test, yPred)\n",
    "print(cm)\n",
    "accuracy_score(test, yPred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4939,)\n",
      "[[2169  236]\n",
      " [ 228 2306]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9060538570560842"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = []\n",
    "openValues = dataset.iloc[:, 34]\n",
    "openValues = np.array(openValues)\n",
    "print(openValues.shape)\n",
    "for i in range(len(yPredClose)):\n",
    "    if yPredClose[i] > openValues[i]:\n",
    "        prediction.append(1)\n",
    "    else:\n",
    "        prediction.append(0)\n",
    "cm = confusion_matrix(test, prediction)\n",
    "print(cm)\n",
    "accuracy_score(test, prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "diffHigh = np.array(diffHigh)\n",
    "diffHigh = diffHigh.reshape(len(diffHigh), 1)\n",
    "diffLow = np.array(diffLow)\n",
    "diffLow = diffLow.reshape(len(diffLow), 1)\n",
    "diffClose = np.array(diffClose)\n",
    "diffClose = diffClose.reshape(len(diffClose), 1)\n",
    "df = pd.DataFrame(np.array(diffClose))\n",
    "diffHigh = np.array(diffHigh)\n",
    "diffLow = np.array(diffLow)\n",
    "df.insert(0, 'close error', diffClose)\n",
    "df.insert(0, 'low error', diffLow)\n",
    "df.insert(0, 'high error', diffHigh)\n",
    "df.to_csv('errors.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      high error   low error  close error\n",
      "0     219.100586   39.240234   104.634766\n",
      "1     345.268555  109.355469   398.299805\n",
      "2     202.134766  167.864258   238.544922\n",
      "3      79.090820   70.453125   213.016602\n",
      "4      20.326172  131.749023   121.743164\n",
      "...          ...         ...          ...\n",
      "4934   56.333984   25.779297    58.035156\n",
      "4935    4.718750   97.664062    40.388672\n",
      "4936   81.675781   19.041016   162.884766\n",
      "4937   90.978516  209.390625   112.894531\n",
      "4938   70.439453   26.228516    12.697266\n",
      "\n",
      "[4939 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('errors.csv')\n",
    "dataset = dataset.iloc[:, 1:-1]\n",
    "print(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in range(4989):\n",
    "    x.append(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [142], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m high \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39miloc[:, \u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m----> 2\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhigh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mblue\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mylabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124merror of high value\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:2790\u001B[0m, in \u001B[0;36mscatter\u001B[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001B[0m\n\u001B[0;32m   2785\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mscatter)\n\u001B[0;32m   2786\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscatter\u001B[39m(\n\u001B[0;32m   2787\u001B[0m         x, y, s\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, c\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, marker\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   2788\u001B[0m         vmin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, vmax\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, linewidths\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   2789\u001B[0m         edgecolors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, plotnonfinite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 2790\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2791\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmarker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmarker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcmap\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2792\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvmax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlinewidths\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlinewidths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2793\u001B[0m \u001B[43m        \u001B[49m\u001B[43medgecolors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medgecolors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplotnonfinite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplotnonfinite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2794\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2795\u001B[0m     sci(__ret)\n\u001B[0;32m   2796\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\__init__.py:1423\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[1;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m   1421\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1423\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1425\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1426\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[0;32m   1427\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:4520\u001B[0m, in \u001B[0;36mAxes.scatter\u001B[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001B[0m\n\u001B[0;32m   4518\u001B[0m y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mma\u001B[38;5;241m.\u001B[39mravel(y)\n\u001B[0;32m   4519\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m!=\u001B[39m y\u001B[38;5;241m.\u001B[39msize:\n\u001B[1;32m-> 4520\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx and y must be the same size\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   4522\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m s \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   4523\u001B[0m     s \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m20\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m mpl\u001B[38;5;241m.\u001B[39mrcParams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_internal.classic_mode\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m\n\u001B[0;32m   4524\u001B[0m          mpl\u001B[38;5;241m.\u001B[39mrcParams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlines.markersize\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2.0\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 2000x300 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "high = dataset.iloc[:, 0].values\n",
    "plt.scatter(x=x, y=high, c='blue')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('error of high value')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counterHigh = 0\n",
    "for i in range(len(high)):\n",
    "    if high[i] < 100:\n",
    "        counterHigh += 1\n",
    "print(counterHigh)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "low = dataset.iloc[:, 1].values\n",
    "plt.scatter(x=x, y=low, c='red')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('error of low value')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counterLow = 0\n",
    "for i in range(len(low)):\n",
    "    if low[i] < 100:\n",
    "        counterLow+=1\n",
    "print(counterLow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "close = dataset.iloc[:, 2].values\n",
    "plt.scatter(x=x, y=close, c='green')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('error of close value')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counterClose = 0\n",
    "for i in range(len(close)):\n",
    "    if close[i] < 100:\n",
    "        counterClose+=1\n",
    "print(counterClose)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"percent of under 100 for high is \" + str((counterHigh/len(high))*100))\n",
    "print(\"percent of under 100 for low is \" + str((counterLow/len(low))*100))\n",
    "print(\"percent of under 100 for close is \" + str((counterClose/len(close))*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counterHigh = 0\n",
    "for i in range(len(high)):\n",
    "    if high[i] < 200:\n",
    "        counterHigh += 1\n",
    "counterLow = 0\n",
    "for i in range(len(low)):\n",
    "    if low[i] < 200:\n",
    "        counterLow+=1\n",
    "counterClose = 0\n",
    "for i in range(len(close)):\n",
    "    if close[i] < 200:\n",
    "        counterClose+=1\n",
    "print(\"percent of under 200 for high is \" + str((counterHigh/len(high))*100))\n",
    "print(\"percent of under 200 for low is \" + str((counterLow/len(low))*100))\n",
    "print(\"percent of under 200 for close is \" + str((counterClose/len(close))*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counterHigh = 0\n",
    "for i in range(len(high)):\n",
    "    if high[i] < 150:\n",
    "        counterHigh += 1\n",
    "counterLow = 0\n",
    "for i in range(len(low)):\n",
    "    if low[i] < 150:\n",
    "        counterLow+=1\n",
    "counterClose = 0\n",
    "for i in range(len(close)):\n",
    "    if close[i] < 150:\n",
    "        counterClose+=1\n",
    "print(\"percent of under 150 for high is \" + str((counterHigh/len(high))*100))\n",
    "print(\"percent of under 150 for low is \" + str((counterLow/len(low))*100))\n",
    "print(\"percent of under 150 for close is \" + str((counterClose/len(close))*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}